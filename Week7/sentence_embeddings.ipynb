{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6be683ff",
      "metadata": {
        "id": "6be683ff"
      },
      "source": [
        "## Deep Learning Study\n",
        "#### Week 7: Language Models(BERT & GPT)\n",
        "![image](https://github.com/HanyangTechAI/2023-Deep-Learning-Study/assets/44901828/cfb43445-7e90-42e4-a442-653fe08c36c5)\n",
        "- BERT는 Transformer 아키텍처를 기반으로 한 모델로, 문장의 의미를 잘 이해하고 문장을 벡터 형태로 변환할 수 있습니다.\n",
        "- Sentence embedding은 문장을 고정된 길이의 벡터로 표현하는 것을 의미하며, 문장 간의 유사도를 계산하는 데 유용합니다. 자세한 내용은 [Weekly NLP week4](https://jiho-ml.com/weekly-nlp-4/)를 참고하세요!\n",
        "- 이번 과제에서는 BERT 모델을 사용하여 문장을 임베딩하고, cosine similarity와 같은 유사도 계산을 수행하여 문장 간의 관계를 분석합니다.\n",
        "- BERT를 사용하여 sentence embedding을 계산하는 방법과 cosine similarity를 계산하는 방법을 학습하고, 주어진 문장들에 대해 이를 적용하여 관계를 파악해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f68e9a77",
      "metadata": {
        "id": "f68e9a77"
      },
      "outputs": [],
      "source": [
        "# 현재 시스템에 transformers와 datasets 라이브러리를 설치합니다.\n",
        "!pip install transformers datasets --quiet\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# GPU 사용 여부\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입력된 문장 사이의 유사도를 계산하기 위해서는, 각 문장의 특성을 잘 파악해 벡터 공간에 대응시키도록 학습된 모델이 필요합니다.\n",
        "- 한국어 문장 임베딩을 계산할 수 있도록 공개된 [레포지토리](https://github.com/BM-K/Sentence-Embedding-Is-All-You-Need)에서 소개된 모델과 토크나이저를 불러와 사용해 보겠습니다."
      ],
      "metadata": {
        "id": "FuDlZ1OI3kDU"
      },
      "id": "FuDlZ1OI3kDU"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model = AutoModel.from_pretrained('BM-K/KoSimCSE-roberta-multitask').to(device).eval()  # or 'BM-K/KoSimCSE-bert-multitask'\n",
        "tokenizer = AutoTokenizer.from_pretrained('BM-K/KoSimCSE-roberta-multitask')  # or 'BM-K/KoSimCSE-bert-multitask'"
      ],
      "metadata": {
        "id": "xswtqgkT3DGt"
      },
      "id": "xswtqgkT3DGt",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://github.com/HanyangTechAI/2023-Deep-Learning-Study/assets/44901828/e988d25c-84c5-4f19-b8a9-dd82ff0bce53)\n",
        "\n",
        "- 유사도를 계산하기 위해 3개의 예시 문장을 준비해 보았습니다.\n",
        "- 미리 불러온 토크나이저를 활용해 입력 문장을 토큰 인덱스의 배열로 변환하고, 모델에 입력하여 출력 결과물을 가져옵니다.\n",
        "- 각각의 문장에 대한 임베딩은 (문장 길이, 모델의 dimension)으로, 문장 사이의 유사도를 계산하기 위해서 0번째 토큰([CLS])에 해당하는 임베딩만 사용합니다."
      ],
      "metadata": {
        "id": "9qXFJrIQzl1q"
      },
      "id": "9qXFJrIQzl1q"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['치타가 들판을 가로 질러 먹이를 쫓는다.',\n",
        "             '치타 한 마리가 먹이 뒤에서 달리고 있다.',\n",
        "             '원숭이 한 마리가 드럼을 연주한다.']\n",
        "\n",
        "# 입력 문장을 tokenizer를 사용하여 토큰 인덱스 배열로 변환합니다.\n",
        "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "# Train을 진행하지 않고 inference만 하기 때문에,\n",
        "# gradient를 계산하지 않도록 하여 메모리 사용량을 절약합니다.\n",
        "with torch.no_grad():\n",
        "  # 모델의 출력값과 loss를 계산합니다. loss는 사용하지 않습니다.\n",
        "  embeddings, loss = model(**inputs, return_dict=False) \n",
        "\n",
        "for i, emb in enumerate(embeddings):\n",
        "  print(f\"{i}번째 문장: {sentences[i]}\")\n",
        "  print(f\"생성된 embedding vector의 shape: {emb.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDrQzwtguelQ",
        "outputId": "760315e9-6d7c-4229-9980-4fc16e06b086"
      },
      "id": "EDrQzwtguelQ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0번째 문장: 치타가 들판을 가로 질러 먹이를 쫓는다.\n",
            "생성된 embedding vector의 shape: torch.Size([15, 768])\n",
            "1번째 문장: 치타 한 마리가 먹이 뒤에서 달리고 있다.\n",
            "생성된 embedding vector의 shape: torch.Size([15, 768])\n",
            "2번째 문장: 원숭이 한 마리가 드럼을 연주한다.\n",
            "생성된 embedding vector의 shape: torch.Size([15, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://github.com/HanyangTechAI/2023-Deep-Learning-Study/assets/44901828/19ece8f7-5c7a-43da-add4-d99f50165863)\n",
        "- 생성된 임베딩의 Cosine similarity를 계산하여 두 문장이 얼마나 의미적으로 유사한지, 즉 임베딩 공간 상에서 얼마나 가까이 있는지 알아보도록 하겠습니다.\n",
        "- Cosine simiarity란 두 벡터 사이의 관계를 계산할 수 있는 방법 중 하나입니다. 두 벡터 사이의 각도 theta가 있을 때, cosine(theta)의 값이 크면 클 수록 두 벡터가 유사하고, 작을수록 다르다는 것을 의미합니다.\n",
        "- Cosine similarity에 대한 자세한 내용이 궁금하다면 [Weekly NLP week5](https://jiho-ml.com/weekly-nlp-5/)를 참고하세요!"
      ],
      "metadata": {
        "id": "zH_mzM7h16YR"
      },
      "id": "zH_mzM7h16YR"
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_score(a, b):\n",
        "    # 0번째 토큰에 해당하는 임베딩 벡터만 사용\n",
        "    a = a[0:1]\n",
        "    b = b[0:1]\n",
        "\n",
        "    # 각 벡터 정규화\n",
        "    a_norm = a / a.norm(dim=1)[:, None]\n",
        "    b_norm = b / b.norm(dim=1)[:, None]\n",
        "\n",
        "    # 정규화된 두 벡터를 곱하여 유사도 점수 계산\n",
        "    return torch.mm(a_norm, b_norm.transpose(0, 1)).item() * 100"
      ],
      "metadata": {
        "id": "lYbSZNLOtkzm"
      },
      "id": "lYbSZNLOtkzm",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 두 문장의 유사도를 계산하는 ```cal_score```함수의 실행 과정은 아래와 같이 이루어집니다.\n",
        "  - 입력된 문장은 각각 (문장 길이, 모델의 hidden dimension(768))의 벡터 형태로 변환됩니다.\n",
        "  - 각 문장의 임베딩 벡터 중 0번째 토큰([CLS])에 해당하는 벡터만 선택합니다. 각각의 벡터는 (1, 768) 형태가 됩니다. \n",
        "  - 두 벡터의 Cosine Similarity를 계산한 뒤 100을 곱해 두 문장의 유사도를 %로 나타냅니다."
      ],
      "metadata": {
        "id": "WuykTl_ryj7W"
      },
      "id": "WuykTl_ryj7W"
    },
    {
      "cell_type": "code",
      "source": [
        "score01 = cal_score(embeddings[0], embeddings[1])  # 약 84%\n",
        "# '치타가 들판을 가로 질러 먹이를 쫓는다.' @ '치타 한 마리가 먹이 뒤에서 달리고 있다.'\n",
        "score02 = cal_score(embeddings[0], embeddings[2])  # 약 23%\n",
        "# '치타가 들판을 가로 질러 먹이를 쫓는다.' @ '원숭이 한 마리가 드럼을 연주한다.'\n",
        "\n",
        "print(f\"'{sentences[0]}'와 '{sentences[1]}'의 유사도: {format(score01, '.2f')}%\")\n",
        "print(f\"'{sentences[0]}'와 '{sentences[2]}'의 유사도: {format(score02, '.2f')}%\")"
      ],
      "metadata": {
        "id": "_EGWKS3WykOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e50f74-eabe-4b7c-97dd-71cfdc652613"
      },
      "id": "_EGWKS3WykOa",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'치타가 들판을 가로 질러 먹이를 쫓는다.'와 '치타 한 마리가 먹이 뒤에서 달리고 있다.'의 유사도: 84.10%\n",
            "'치타가 들판을 가로 질러 먹이를 쫓는다.'와 '원숭이 한 마리가 드럼을 연주한다.'의 유사도: 23.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Huggingface는 다양한 언어와 task를 사용하는 데이터셋을 쉽게 사용할 수 있도록 하는 **dataset** 라이브러리를 제공합니다.\n",
        "- Huggingface는 model hub와 마찬가지로 다양한 데이터셋을 찾을 수 있는 [dataset hub](https://huggingface.co/datasets)도 운영하고 있습니다.\n",
        "- 네이버 뉴스 기사를 저장해둔 텍스트 데이터셋을 불러와서 살펴보도록 하겠습니다."
      ],
      "metadata": {
        "id": "WjZH4Qg2ymLP"
      },
      "id": "WjZH4Qg2ymLP"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# 네이버 뉴스 요약 데이터셋 다운로드\n",
        "# 데이터셋 주소\n",
        "naver_news = load_dataset(\"daekeun-ml/naver-news-summarization-ko\")"
      ],
      "metadata": {
        "id": "B_ymtXrgynsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88,
          "referenced_widgets": [
            "c2284458509147f49b5f3fbbc031efaa",
            "c995c7658be7408f9cc7cb25ca2c3252",
            "e4f9f1dc8fd34b64bd0f099b1fc649c3",
            "41fc4f4dab964b2e88f113c7f861b320",
            "1cbb7da66a5543ae8f41745fe854143d",
            "52242d249b3e478b82e2907d13604513",
            "81a804d7046442c481ec1a8a01e0ea81",
            "f7fb47f93fc84bb68b017c206fcd770a",
            "6d0eb964f2374e0b91c0c2d4e375f7a0",
            "4dd8617a485c4e7f80314327b2c1e42c",
            "77a5d2b958404b2dac21269abb279f75"
          ]
        },
        "outputId": "09f38f43-4e3b-40bc-9338-2b17065c0cdc"
      },
      "id": "B_ymtXrgynsV",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/daekeun-ml___csv/daekeun-ml--naver-news-summarization-ko-884ccea06154613b/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2284458509147f49b5f3fbbc031efaa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 다운로드한 데이터셋을 살펴보면, train/validation/test 세 가지의 split으로 구성되어 있는 것을 볼 수 있습니다.\n",
        "- test split을 선택해보면, 각각의 데이터셋은 table 형태로 구성되어 있고, 날짜, 제목, 본문, 요약문 등 다양한 column이 존재하는 것을 알 수 있습니다.\n",
        "- 데이터셋에서 뉴스 제목을 500개 정도만 추출하여 사용해 보겠습니다."
      ],
      "metadata": {
        "id": "5p9bNa7Ryps2"
      },
      "id": "5p9bNa7Ryps2"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"전체 데이터셋:\\n\", naver_news)\n",
        "print(\"Test split:\\n\", naver_news[\"test\"])\n",
        "\n",
        "news_titles = naver_news[\"test\"][\"title\"][:500]\n",
        "print(\"뉴스 제목:\")\n",
        "for title in news_titles[:5]:\n",
        "  print(title)"
      ],
      "metadata": {
        "id": "YVUxwECOyrCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abc83d3-f8bb-4480-b846-23a0be3a9b07"
      },
      "id": "YVUxwECOyrCj",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 데이터셋:\n",
            " DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
            "        num_rows: 22194\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
            "        num_rows: 2466\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
            "        num_rows: 2740\n",
            "    })\n",
            "})\n",
            "Test split:\n",
            " Dataset({\n",
            "    features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
            "    num_rows: 2740\n",
            "})\n",
            "뉴스 제목:\n",
            "아이트로닉스 차량용 복합기능형 졸음 방지 단말기 특허 출원\n",
            "뉴스페이스로 가는 한국… 우주기업 성장할 기술·터전 만든다\n",
            "SP500 올 상반기 21%↓…50년래 최악 월가월부\n",
            "풀무원 알래스칸 명태살 ‘볼카츠’ 출시\n",
            "일동제약 생산본부장에 강덕원 부사장 영입\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 여기부터 과제 시작\n",
        "----\n",
        "# 7주차 과제: Sentence embedding을 활용한 뉴스 제목 추천\n",
        "- 위에서 사용했던 BERT 모델을 이용하여, 사용자가 입력한 내용과 가장 유사한 뉴스 제목을 찾아 추천해주는 프로그램을 만들어 봅시다.\n",
        "- 프로그램의 뼈대를 이루는 함수 이름과 정의가 마련되어 있으니, 필요한 부분을 자유롭게 구성하여 프로그램을 완성해 봅시다.\n",
        "- ***주의: main 함수의 정의는 바꾸지 마세요!***\n",
        "\n",
        "### 작동 예시\n",
        "```\n",
        "입력 > 신재생 에너지\n",
        "출력 > 입력과 유사한 상위 5개의 뉴스 제목을 출력합니다.\n",
        "1. 에너지정책 유턴  재생에너지 대신 원전으로\t(score: 56.85)\n",
        "2. 전기 아껴쓴 만큼 현금 돌려받는다...에너지캐쉬백 전국 확대\t(score: 54.78)\n",
        "3. 수자원공사 한국에너지기술연과 그린수소 연구 업무협약\t(score: 53.07)\n",
        "4. 이어지는 폭염 늘어나는 전력수요\t(score: 51.01)\n",
        "5. 코오롱 수소 밸류체인 플랫폼 구축… 생산부터 발전까지 원스톱\t(score: 50.95)\n",
        "```\n",
        "\n",
        "### Hint\n",
        "- Hint 1: news_title에는 뉴스 데이터셋에 포함되어 있는 각 뉴스 기사들의 제목이 포함되어 있습니다. 예시 문장의 임베딩을 계산한 것과 같은 방식을 사용할 수 있습니다.\n",
        "- Hint 2: 위에서 정의하고 사용했던 ```cal_score``` 함수를 사용하면 사용자가 입력한 요청사항과 뉴스 제목들 사이의 similarity score를 계산할 수 있습니다."
      ],
      "metadata": {
        "id": "snT-cBMyys77"
      },
      "id": "snT-cBMyys77"
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def get_sentence_embeddings(sentences):\n",
        "  # 입력 문장을 tokenizer를 사용하여 토큰 인덱스 배열로 변환합니다.\n",
        "  inputs = None\n",
        "  # 모델을 활용하여 임베딩을 계산합니다..\n",
        "  with torch.no_grad():\n",
        "    embeddings, loss = None\n",
        "  return embeddings\n",
        "\n",
        "def get_similarity_scores(embeddings, input_text):\n",
        "  # 입력 텍스트에 대한 임베딩을 계산합니다.\n",
        "  input_embedding = None\n",
        "\n",
        "  # 입력 텍스트의 임베딩과 미리 계산된 임베딩 사이의 유사도를 계산합니다.\n",
        "  scores = []\n",
        "  for emb in embeddings:\n",
        "    scores.append(None)\n",
        "\n",
        "  return scores"
      ],
      "metadata": {
        "id": "nIyCBeWwyvPH"
      },
      "id": "nIyCBeWwyvPH",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 부분은 수정하지 마세요!\n",
        "\n",
        "def main():\n",
        "  # 뉴스 기사 제목의 임베딩 벡터 계산\n",
        "  news_embeddings = get_sentence_embeddings(news_titles)\n",
        "\n",
        "  input_text = input(\"입력 > \")\n",
        "  # 입력된 텍스트와 뉴스 기사 제목들 사이의 유사도 계산\n",
        "  similarity_scores = get_similarity_scores(news_embeddings, input_text)\n",
        "\n",
        "  print(\"출력 > 입력과 유사한 상위 5개의 뉴스 제목을 출력합니다.\")\n",
        "  # 유사도 점수가 가장 높은 5개의 index 찾기\n",
        "  top_5_idx = reversed(np.argsort(similarity_scores)[-5:])\n",
        "\n",
        "  # 각 index에 해당하는 뉴스 제목과 유사도 점수 출력\n",
        "  for i, idx in enumerate(top_5_idx):\n",
        "    print(f\"{i+1}. {news_titles[idx]}\\t(score: {format(similarity_scores[idx], '.2f')})\")\n",
        "\n",
        "# 프로그램 실행\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UukdvRIgMeTg",
        "outputId": "f385d564-8eb5-403e-9db9-1e511cf5e540"
      },
      "id": "UukdvRIgMeTg",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 > 신재생 에너지\n",
            "출력 > 입력과 유사한 상위 5개의 뉴스 제목을 출력합니다.\n",
            "1. 에너지정책 유턴  재생에너지 대신 원전으로\t(score: 56.85)\n",
            "2. 전기 아껴쓴 만큼 현금 돌려받는다...에너지캐쉬백 전국 확대\t(score: 54.78)\n",
            "3. 수자원공사 한국에너지기술연과 그린수소 연구 업무협약\t(score: 53.07)\n",
            "4. 이어지는 폭염 늘어나는 전력수요\t(score: 51.01)\n",
            "5. 코오롱 수소 밸류체인 플랫폼 구축… 생산부터 발전까지 원스톱\t(score: 50.95)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2284458509147f49b5f3fbbc031efaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c995c7658be7408f9cc7cb25ca2c3252",
              "IPY_MODEL_e4f9f1dc8fd34b64bd0f099b1fc649c3",
              "IPY_MODEL_41fc4f4dab964b2e88f113c7f861b320"
            ],
            "layout": "IPY_MODEL_1cbb7da66a5543ae8f41745fe854143d"
          }
        },
        "c995c7658be7408f9cc7cb25ca2c3252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52242d249b3e478b82e2907d13604513",
            "placeholder": "​",
            "style": "IPY_MODEL_81a804d7046442c481ec1a8a01e0ea81",
            "value": "100%"
          }
        },
        "e4f9f1dc8fd34b64bd0f099b1fc649c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7fb47f93fc84bb68b017c206fcd770a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d0eb964f2374e0b91c0c2d4e375f7a0",
            "value": 3
          }
        },
        "41fc4f4dab964b2e88f113c7f861b320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dd8617a485c4e7f80314327b2c1e42c",
            "placeholder": "​",
            "style": "IPY_MODEL_77a5d2b958404b2dac21269abb279f75",
            "value": " 3/3 [00:00&lt;00:00, 107.75it/s]"
          }
        },
        "1cbb7da66a5543ae8f41745fe854143d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52242d249b3e478b82e2907d13604513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81a804d7046442c481ec1a8a01e0ea81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7fb47f93fc84bb68b017c206fcd770a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d0eb964f2374e0b91c0c2d4e375f7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dd8617a485c4e7f80314327b2c1e42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a5d2b958404b2dac21269abb279f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}